rm_toxicity:
  seed: 1
  out_features: 7
  reward_model_name: gpt2
  loss_fn: cumulative_mse
  learning_rate: 2e-5
  adam_beta1: 0.9
  adam_beta2: 0.95
  adam_epsilon: 1e-12
  weight_decay: 0.01
  warmup_steps: 1000
  per_device_train_batch_size: 100
  per_device_eval_batch_size: 100
  num_train_epochs: 1
  eval_steps: 1000
  save_strategy: steps
  save_steps: 1000
  max_length: 1024
  logging_steps: 100
  max_grad_norm: 2.0
  save_total_limit: 10
  dtype: float32
  datasets:
    - jigsaw_unintended_bias
  eval_size: 1000
  verbose: true
  log_wandb: true
  metrics: mse
  jigsaw_dir: ../datasets/PATH_TO_JIGSAW_DATASET
  output_dir: saved_models/gpt2_toxicity_backup


rm_sentiment:
  seed: 1
  out_features: 1
  reward_model_name: gpt2
  loss_fn: cumulative_mse
  learning_rate: 2e-5
  adam_beta1: 0.9
  adam_beta2: 0.95
  adam_epsilon: 1e-12
  weight_decay: 0.01
  warmup_steps: 1000
  per_device_train_batch_size: 100
  per_device_eval_batch_size: 100
  num_train_epochs: 1
  eval_steps: 1000
  save_strategy: steps
  save_steps: 1000
  max_length: 1024
  logging_steps: 100
  max_grad_norm: 2.0
  save_total_limit: 10
  dtype: float32
  datasets:
    - sst2
    - amazon_polarity
  eval_size: 1000
  verbose: true
  log_wandb: true
  metrics: mse
  jigsaw_dir: null
  output_dir: saved_models/gpt2_sentiment_backup


gpt2-small:
  reward_model_name: gpt2
  max_length: 1024
  dtype: float32